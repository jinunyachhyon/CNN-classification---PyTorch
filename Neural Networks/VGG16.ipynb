{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:47.502291Z","iopub.execute_input":"2023-05-04T03:55:47.502667Z","iopub.status.idle":"2023-05-04T03:55:51.742160Z","shell.execute_reply.started":"2023-05-04T03:55:47.502636Z","shell.execute_reply":"2023-05-04T03:55:51.741112Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# random seed --> reproducibility\nimport random\nrandom.seed(42)\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:51.744586Z","iopub.execute_input":"2023-05-04T03:55:51.745325Z","iopub.status.idle":"2023-05-04T03:55:51.758666Z","shell.execute_reply.started":"2023-05-04T03:55:51.745281Z","shell.execute_reply":"2023-05-04T03:55:51.757410Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7820a4e46ad0>"},"metadata":{}}]},{"cell_type":"code","source":"# transforms\ndata_transforms = {\n    'train': transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomRotation(5),    \n    transforms.RandomHorizontalFlip(0.5),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]),\n\n    'test': transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(0.5),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n}","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:51.764752Z","iopub.execute_input":"2023-05-04T03:55:51.765097Z","iopub.status.idle":"2023-05-04T03:55:51.771706Z","shell.execute_reply.started":"2023-05-04T03:55:51.765067Z","shell.execute_reply":"2023-05-04T03:55:51.770551Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/chest-xray-pneumonia/chest_xray/train'\ntest_dir = '../input/chest-xray-pneumonia/chest_xray/test'","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:51.773203Z","iopub.execute_input":"2023-05-04T03:55:51.773839Z","iopub.status.idle":"2023-05-04T03:55:51.785121Z","shell.execute_reply.started":"2023-05-04T03:55:51.773804Z","shell.execute_reply":"2023-05-04T03:55:51.783960Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data = datasets.ImageFolder(root=train_dir, transform=data_transforms['train'])\ntest_data = datasets.ImageFolder(root=test_dir, transform=data_transforms['test'])","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:51.786858Z","iopub.execute_input":"2023-05-04T03:55:51.787223Z","iopub.status.idle":"2023-05-04T03:55:53.326025Z","shell.execute_reply.started":"2023-05-04T03:55:51.787191Z","shell.execute_reply":"2023-05-04T03:55:53.325217Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:53.327084Z","iopub.execute_input":"2023-05-04T03:55:53.327836Z","iopub.status.idle":"2023-05-04T03:55:53.332990Z","shell.execute_reply.started":"2023-05-04T03:55:53.327803Z","shell.execute_reply":"2023-05-04T03:55:53.332217Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset ImageFolder\n    Number of datapoints: 5216\n    Root location: ../input/chest-xray-pneumonia/chest_xray/train\n    StandardTransform\nTransform: Compose(\n               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n               RandomRotation(degrees=[-5.0, 5.0], interpolation=nearest, expand=False, fill=0)\n               RandomHorizontalFlip(p=0.5)\n               ToTensor()\n               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n           )"},"metadata":{}}]},{"cell_type":"code","source":"# DataLoader object creation for batch \ntrain_loader = torch.utils.data.DataLoader(train_data,\n                                           batch_size = 64,\n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(test_data,\n                                           batch_size = 64,\n                                           shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:53.334432Z","iopub.execute_input":"2023-05-04T03:55:53.334992Z","iopub.status.idle":"2023-05-04T03:55:53.346791Z","shell.execute_reply.started":"2023-05-04T03:55:53.334957Z","shell.execute_reply":"2023-05-04T03:55:53.345910Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# example\niterate = iter(train_loader)\nsample, labels = next(iterate)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:53.348047Z","iopub.execute_input":"2023-05-04T03:55:53.348605Z","iopub.status.idle":"2023-05-04T03:55:55.454779Z","shell.execute_reply.started":"2023-05-04T03:55:53.348562Z","shell.execute_reply":"2023-05-04T03:55:55.453263Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sample.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.461266Z","iopub.execute_input":"2023-05-04T03:55:55.462356Z","iopub.status.idle":"2023-05-04T03:55:55.469942Z","shell.execute_reply.started":"2023-05-04T03:55:55.462308Z","shell.execute_reply":"2023-05-04T03:55:55.468845Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 3, 224, 224])"},"metadata":{}}]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.471441Z","iopub.execute_input":"2023-05-04T03:55:55.471814Z","iopub.status.idle":"2023-05-04T03:55:55.487374Z","shell.execute_reply.started":"2023-05-04T03:55:55.471777Z","shell.execute_reply":"2023-05-04T03:55:55.485800Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n        1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"class VGG16(nn.Module):\n    def __init__(self):\n        super(VGG16,self).__init__()\n        \n        self.features = torch.nn.Sequential(\n            # conv layer 1\n            nn.Conv2d(in_channels=3,\n                      out_channels=6,\n                      kernel_size=3,\n                      padding=1),   \n            nn.ReLU(inplace=True),\n            \n            # conv layer 2\n            nn.Conv2d(in_channels=6,\n                      out_channels=10,\n                      kernel_size=3,\n                      padding=1),\n            nn.MaxPool2d(kernel_size=2),\n            nn.ReLU(inplace=True),\n            \n            # conv layer 3\n            nn.Conv2d(in_channels=10,\n                      out_channels=12,\n                      kernel_size=3,\n                      padding=1),   \n            nn.ReLU(inplace=True),\n            \n            # conv layer 4\n            nn.Conv2d(in_channels=12,\n                      out_channels=14,\n                      kernel_size=3,\n                      padding=1), \n            nn.MaxPool2d(kernel_size=2),\n            nn.ReLU(inplace=True),\n            \n            # conv layer 5\n            nn.Conv2d(in_channels=14,\n                      out_channels=16,\n                      kernel_size=3,\n                      padding=1),   \n            nn.ReLU(inplace=True),\n            \n            # conv layer 6\n            nn.Conv2d(in_channels=16,\n                      out_channels=18,\n                      kernel_size=3,\n                      padding=1),   \n            nn.ReLU(inplace=True),\n            \n            # conv layer 7\n            nn.Conv2d(in_channels=18,\n                      out_channels=20,\n                      kernel_size=3,\n                      padding=1), \n            nn.MaxPool2d(kernel_size=2),\n            nn.ReLU(inplace=True),\n            \n            # conv layer 8\n            nn.Conv2d(in_channels=20,\n                      out_channels=22,\n                      kernel_size=3,\n                      padding=1),   \n            nn.ReLU(inplace=True),\n            \n            # conv layer 9\n            nn.Conv2d(in_channels=22,\n                      out_channels=24,\n                      kernel_size=3,\n                      padding=1),   \n            nn.ReLU(inplace=True),\n            \n            # conv layer 10\n            nn.Conv2d(in_channels=24,\n                      out_channels=26,\n                      kernel_size=3,\n                      padding=1),\n            nn.MaxPool2d(kernel_size=2),\n            nn.ReLU(inplace=True),\n            \n            # conv layer 11\n            nn.Conv2d(in_channels=26,\n                      out_channels=28,\n                      kernel_size=3,\n                      padding=1),   \n            nn.ReLU(inplace=True),\n            \n            # conv layer 12\n            nn.Conv2d(in_channels=28,\n                      out_channels=30,\n                      kernel_size=3,\n                      padding=1),   \n            nn.ReLU(inplace=True),\n            \n            # conv layer 13\n            nn.Conv2d(in_channels=30,\n                      out_channels=32,\n                      kernel_size=3,\n                      padding=1),\n            nn.MaxPool2d(kernel_size=2),\n            nn.ReLU(inplace=True))\n                \n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n            \n        self.classifier = torch.nn.Sequential(\n            #linear layer 1\n            nn.Linear(32*7*7, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n        \n            #linear layer 2\n            nn.Linear(512,512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n        \n            #linear layer 3\n            nn.Linear(512,2))\n        \n    def forward(self,x):\n        # convolution\n        x = self.features(x)\n        \n        # adaptive average pooling\n        x = self.avgpool(x)\n        \n        #flatten\n        x = x.view(-1, 32*7*7)\n        \n        # fully connected layer\n        x = self.classifier(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.488978Z","iopub.execute_input":"2023-05-04T03:55:55.489404Z","iopub.status.idle":"2023-05-04T03:55:55.507363Z","shell.execute_reply.started":"2023-05-04T03:55:55.489372Z","shell.execute_reply":"2023-05-04T03:55:55.505918Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# model -- class object\nmodel = VGG16()","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.508933Z","iopub.execute_input":"2023-05-04T03:55:55.509418Z","iopub.status.idle":"2023-05-04T03:55:55.540802Z","shell.execute_reply.started":"2023-05-04T03:55:55.509367Z","shell.execute_reply":"2023-05-04T03:55:55.539202Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.542350Z","iopub.execute_input":"2023-05-04T03:55:55.542693Z","iopub.status.idle":"2023-05-04T03:55:55.550443Z","shell.execute_reply.started":"2023-05-04T03:55:55.542664Z","shell.execute_reply":"2023-05-04T03:55:55.549325Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"VGG16(\n  (features): Sequential(\n    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): ReLU(inplace=True)\n    (5): Conv2d(10, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(16, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(18, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(20, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(22, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(24, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (23): ReLU(inplace=True)\n    (24): Conv2d(26, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(28, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (30): ReLU(inplace=True)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=1568, out_features=512, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=512, out_features=512, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=512, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.552518Z","iopub.execute_input":"2023-05-04T03:55:55.552869Z","iopub.status.idle":"2023-05-04T03:55:55.562180Z","shell.execute_reply.started":"2023-05-04T03:55:55.552837Z","shell.execute_reply":"2023-05-04T03:55:55.561224Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"The model has 1,115,490 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"# loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.563384Z","iopub.execute_input":"2023-05-04T03:55:55.564369Z","iopub.status.idle":"2023-05-04T03:55:55.576788Z","shell.execute_reply.started":"2023-05-04T03:55:55.564331Z","shell.execute_reply":"2023-05-04T03:55:55.575837Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# total iteration\nlen(train_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.578036Z","iopub.execute_input":"2023-05-04T03:55:55.579056Z","iopub.status.idle":"2023-05-04T03:55:55.589524Z","shell.execute_reply.started":"2023-05-04T03:55:55.579022Z","shell.execute_reply":"2023-05-04T03:55:55.588176Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"82"},"metadata":{}}]},{"cell_type":"code","source":"total_batches = len(train_loader)\n\nfor epoch in range(10):\n    for i , (images, labels) in enumerate(train_loader):\n        \n        # forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 40 == 0:\n            print(f'Epoch [{epoch+1}/{10}], step [{i+1}/{total_batches}], loss:{loss.item():.4f}')\n            \nprint('Finished Training')    ","metadata":{"execution":{"iopub.status.busy":"2023-05-04T03:55:55.590836Z","iopub.execute_input":"2023-05-04T03:55:55.591160Z","iopub.status.idle":"2023-05-04T04:41:21.913087Z","shell.execute_reply.started":"2023-05-04T03:55:55.591132Z","shell.execute_reply":"2023-05-04T04:41:21.911824Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch [1/10], step [40/82], loss:0.6662\nEpoch [1/10], step [80/82], loss:0.6052\nEpoch [2/10], step [40/82], loss:0.6268\nEpoch [2/10], step [80/82], loss:0.5268\nEpoch [3/10], step [40/82], loss:0.5108\nEpoch [3/10], step [80/82], loss:0.5284\nEpoch [4/10], step [40/82], loss:0.6001\nEpoch [4/10], step [80/82], loss:0.5188\nEpoch [5/10], step [40/82], loss:0.6200\nEpoch [5/10], step [80/82], loss:0.6154\nEpoch [6/10], step [40/82], loss:0.5239\nEpoch [6/10], step [80/82], loss:0.4965\nEpoch [7/10], step [40/82], loss:0.6531\nEpoch [7/10], step [80/82], loss:0.7041\nEpoch [8/10], step [40/82], loss:0.5538\nEpoch [8/10], step [80/82], loss:0.5109\nEpoch [9/10], step [40/82], loss:0.6369\nEpoch [9/10], step [80/82], loss:0.6530\nEpoch [10/10], step [40/82], loss:0.4899\nEpoch [10/10], step [80/82], loss:0.6027\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"# save this model\ntorch.save(model.state_dict(), 'modelVGG16.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:41:21.914704Z","iopub.execute_input":"2023-05-04T04:41:21.915094Z","iopub.status.idle":"2023-05-04T04:41:21.928544Z","shell.execute_reply.started":"2023-05-04T04:41:21.915064Z","shell.execute_reply":"2023-05-04T04:41:21.927434Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# evaluation and testing \nwith torch.no_grad():\n    n_correct =0\n    n_samples =0\n    \n    for images, labels in test_loader:\n        # forward -- softmax prediction \n        outputs = model(images)\n        \n        # actual prediction\n        # value, index\n        _, predictions = torch.max(outputs, 1) # multiclass pred\n        n_samples += labels.shape[0]\n        n_correct += (predictions==labels).sum().item()\n        \n    acc = 100.0 * n_correct / n_samples\n    print(acc)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:41:21.930238Z","iopub.execute_input":"2023-05-04T04:41:21.930890Z","iopub.status.idle":"2023-05-04T04:41:48.261692Z","shell.execute_reply.started":"2023-05-04T04:41:21.930836Z","shell.execute_reply":"2023-05-04T04:41:48.260819Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"62.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Initializing parameters to compare evaluation","metadata":{}},{"cell_type":"code","source":"## with initializing parameters\ndef initialize_parameters(m):\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n        nn.init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.Linear):\n        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n        nn.init.constant_(m.bias.data, 0)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:41:48.263227Z","iopub.execute_input":"2023-05-04T04:41:48.263896Z","iopub.status.idle":"2023-05-04T04:41:48.269787Z","shell.execute_reply.started":"2023-05-04T04:41:48.263861Z","shell.execute_reply":"2023-05-04T04:41:48.268420Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.apply(initialize_parameters)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:41:48.271631Z","iopub.execute_input":"2023-05-04T04:41:48.272032Z","iopub.status.idle":"2023-05-04T04:41:48.297721Z","shell.execute_reply.started":"2023-05-04T04:41:48.271976Z","shell.execute_reply":"2023-05-04T04:41:48.296518Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"VGG16(\n  (features): Sequential(\n    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(6, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): ReLU(inplace=True)\n    (5): Conv2d(10, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(12, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(16, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(18, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(20, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(22, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(24, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (23): ReLU(inplace=True)\n    (24): Conv2d(26, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(28, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (30): ReLU(inplace=True)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=1568, out_features=512, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=512, out_features=512, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=512, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"total_batches = len(train_loader)\n\nfor epoch in range(10):\n    for i , (images, labels) in enumerate(train_loader):\n        \n        # forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 40 == 0:\n            print(f'Epoch [{epoch+1}/{10}], step [{i+1}/{total_batches}], loss:{loss.item():.4f}')\n            \nprint('Finished Training')    ","metadata":{"execution":{"iopub.status.busy":"2023-05-04T04:41:48.299242Z","iopub.execute_input":"2023-05-04T04:41:48.299581Z","iopub.status.idle":"2023-05-04T05:27:21.196576Z","shell.execute_reply.started":"2023-05-04T04:41:48.299550Z","shell.execute_reply":"2023-05-04T05:27:21.195669Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch [1/10], step [40/82], loss:0.2430\nEpoch [1/10], step [80/82], loss:0.2869\nEpoch [2/10], step [40/82], loss:0.0822\nEpoch [2/10], step [80/82], loss:0.0880\nEpoch [3/10], step [40/82], loss:0.1925\nEpoch [3/10], step [80/82], loss:0.1317\nEpoch [4/10], step [40/82], loss:0.1692\nEpoch [4/10], step [80/82], loss:0.0870\nEpoch [5/10], step [40/82], loss:0.0787\nEpoch [5/10], step [80/82], loss:0.0958\nEpoch [6/10], step [40/82], loss:0.0455\nEpoch [6/10], step [80/82], loss:0.0420\nEpoch [7/10], step [40/82], loss:0.0127\nEpoch [7/10], step [80/82], loss:0.1324\nEpoch [8/10], step [40/82], loss:0.0538\nEpoch [8/10], step [80/82], loss:0.0568\nEpoch [9/10], step [40/82], loss:0.0665\nEpoch [9/10], step [80/82], loss:0.0600\nEpoch [10/10], step [40/82], loss:0.0817\nEpoch [10/10], step [80/82], loss:0.1431\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"# save this model\ntorch.save(model.state_dict(), 'modelVGG16_initialparam.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-04T05:27:21.198712Z","iopub.execute_input":"2023-05-04T05:27:21.199044Z","iopub.status.idle":"2023-05-04T05:27:21.211540Z","shell.execute_reply.started":"2023-05-04T05:27:21.199016Z","shell.execute_reply":"2023-05-04T05:27:21.210452Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# evaluation and testing \nwith torch.no_grad():\n    n_correct =0\n    n_samples =0\n    \n    for images, labels in test_loader:\n        # forward -- softmax prediction \n        outputs = model(images)\n        \n        # actual prediction\n        # value, index\n        _, predictions = torch.max(outputs, 1) # multiclass pred\n        n_samples += labels.shape[0]\n        n_correct += (predictions==labels).sum().item()\n        \n    acc = 100.0 * n_correct / n_samples\n    print(acc)","metadata":{"execution":{"iopub.status.busy":"2023-05-04T05:27:21.213034Z","iopub.execute_input":"2023-05-04T05:27:21.213933Z","iopub.status.idle":"2023-05-04T05:27:41.547160Z","shell.execute_reply.started":"2023-05-04T05:27:21.213897Z","shell.execute_reply":"2023-05-04T05:27:41.545821Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"78.68589743589743\n","output_type":"stream"}]}]}